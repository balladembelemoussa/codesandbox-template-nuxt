{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/balladembelemoussa/codesandbox-template-nuxt/blob/main/pCopie_de_Untitled.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Apprentissage automatique - Validation croisée**"
      ],
      "metadata": {
        "id": "5IN5wpXZH34M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validation croisée\n",
        "Lors de l'ajustement des modèles, nous visons à augmenter les performances globales du modèle sur des données invisibles. Le réglage des hyperparamètres peut conduire à de bien meilleures performances sur les ensembles de test. Cependant, l'optimisation des paramètres de l'ensemble de test peut entraîner une fuite d'informations, ce qui entraîne une détérioration du modèle sur des données invisibles. Pour corriger cela, nous pouvons effectuer une validation croisée.\n",
        "\n",
        "Pour mieux comprendre le CV, nous appliquerons différentes méthodes sur l'ensemble de données de l'iris. Commençons par charger et séparer les données."
      ],
      "metadata": {
        "id": "NZat7qPWH7oK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "\n",
        "X, y = datasets.load_iris(return_X_y=True)"
      ],
      "metadata": {
        "id": "8O9drbAeIDMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il existe de nombreuses méthodes de validation croisée, nous commencerons par examiner la validation croisée k-fold.\n",
        "\n",
        "Pliage en K\n",
        "Les données d'apprentissage utilisées dans le modèle sont divisées en un nombre k d'ensembles plus petits, à utiliser pour valider le modèle. Le modèle est ensuite entraîné sur k-1 plis de l'ensemble d'entraînement. Le pli restant est ensuite utilisé comme ensemble de validation pour évaluer le modèle.\n",
        "\n",
        "Comme nous allons essayer de classer différentes espèces de fleurs d'iris, nous devrons importer un modèle de classificateur. Pour cet exercice, nous utiliserons un fichier DecisionTreeClassifier. Nous devrons également importer des modules CV à partir de sklearn."
      ],
      "metadata": {
        "id": "SeRaD0GcIUZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import KFold, cross_val_score"
      ],
      "metadata": {
        "id": "U3aP1Vi6IXth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Avec les données chargées, nous pouvons maintenant créer et ajuster un modèle pour l'évaluation."
      ],
      "metadata": {
        "id": "XtirGXxaIbQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = DecisionTreeClassifier(random_state=42)"
      ],
      "metadata": {
        "id": "PY7hWDPTIeEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Évaluons maintenant notre modèle et voyons comment il se comporte sur chaque k -fold."
      ],
      "metadata": {
        "id": "Rg2xey6QIl3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k_folds = KFold(n_splits = 5)\n",
        "\n",
        "scores = cross_val_score(clf, X, y, cv = k_folds)"
      ],
      "metadata": {
        "id": "Pdffx_PIIm-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il est également recommandé de voir comment CV s'est comporté globalement en faisant la moyenne des scores pour tous les plis.\n",
        "\n",
        "Exemple\n",
        "Exécutez le CV k-fold :"
      ],
      "metadata": {
        "id": "Z6wCOS-bIsI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "\n",
        "X, y = datasets.load_iris(return_X_y=True)\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "k_folds = KFold(n_splits = 5)\n",
        "\n",
        "scores = cross_val_score(clf, X, y, cv = k_folds)\n",
        "\n",
        "print(\"Cross Validation Scores: \", scores)\n",
        "print(\"Average CV Score: \", scores.mean())\n",
        "print(\"Number of CV Scores used in Average: \", len(scores))"
      ],
      "metadata": {
        "id": "QHcRpjNTI9XC",
        "outputId": "9d7e152f-ae2f-4bb9-960c-545217775c55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross Validation Scores:  [1.         1.         0.83333333 0.93333333 0.8       ]\n",
            "Average CV Score:  0.9133333333333333\n",
            "Number of CV Scores used in Average:  5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pliage en K stratifié\n",
        "Dans les cas où les classes sont déséquilibrées, nous avons besoin d'un moyen de tenir compte du déséquilibre dans les ensembles de train et de validation. Pour ce faire, nous pouvons stratifier les classes cibles, ce qui signifie que les deux ensembles auront une proportion égale de toutes les classes.\n",
        "\n",
        "Exemple"
      ],
      "metadata": {
        "id": "t92QKk1TJCj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "\n",
        "X, y = datasets.load_iris(return_X_y=True)\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "sk_folds = StratifiedKFold(n_splits = 5)\n",
        "\n",
        "scores = cross_val_score(clf, X, y, cv = sk_folds)\n",
        "\n",
        "print(\"Cross Validation Scores: \", scores)\n",
        "print(\"Average CV Score: \", scores.mean())\n",
        "print(\"Number of CV Scores used in Average: \", len(scores))"
      ],
      "metadata": {
        "id": "p8Xm2aj1JF49",
        "outputId": "e768caf3-c29c-47a5-c815-26f5d1d5a8de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross Validation Scores:  [0.96666667 0.96666667 0.9        0.93333333 1.        ]\n",
            "Average CV Score:  0.9533333333333334\n",
            "Number of CV Scores used in Average:  5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alors que le nombre de plis est le même, le CV moyen augmente à partir du k-pli de base en s'assurant qu'il y a des classes stratifiées.\n",
        "\n",
        "Leave-One-Out (LOO)\n",
        "Au lieu de sélectionner le nombre de fractionnements dans l'ensemble de données d'entraînement comme K-fold LeaveOneOut, utilisez 1 observation pour valider et n-1 observations pour l'entraînement. Cette méthode est une technique exhaustive.\n",
        "\n",
        "Exemple\n",
        "Exécutez LOO CV :"
      ],
      "metadata": {
        "id": "aH_y0U2uJJwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import LeaveOneOut, cross_val_score\n",
        "\n",
        "X, y = datasets.load_iris(return_X_y=True)\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "loo = LeaveOneOut()\n",
        "\n",
        "scores = cross_val_score(clf, X, y, cv = loo)\n",
        "\n",
        "print(\"Cross Validation Scores: \", scores)\n",
        "print(\"Average CV Score: \", scores.mean())\n",
        "print(\"Number of CV Scores used in Average: \", len(scores))"
      ],
      "metadata": {
        "id": "fHROyNwqJNGA",
        "outputId": "e8c015b8-851a-4872-a65f-c54849b6e104",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross Validation Scores:  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
            " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1.]\n",
            "Average CV Score:  0.94\n",
            "Number of CV Scores used in Average:  150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous pouvons observer que le nombre de scores de validation croisée effectués est égal au nombre d'observations dans l'ensemble de données. Dans ce cas, il y a 150 observations dans le jeu de données de l'iris.\n",
        "\n",
        "Le score CV moyen est de 94 %.\n",
        "\n",
        "Sans sortie (LPO)\n",
        "Leave-P-Out est simplement une différence nuancée par rapport à l'idée Leave-One-Out, en ce sens que nous pouvons sélectionner le nombre de p à utiliser dans notre ensemble de validation.\n",
        "\n",
        "Exemple\n",
        "Exécutez le CV LPO"
      ],
      "metadata": {
        "id": "gmt0P942JTQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import LeavePOut, cross_val_score\n",
        "\n",
        "X, y = datasets.load_iris(return_X_y=True)\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "lpo = LeavePOut(p=2)\n",
        "\n",
        "scores = cross_val_score(clf, X, y, cv = lpo)\n",
        "\n",
        "print(\"Cross Validation Scores: \", scores)\n",
        "print(\"Average CV Score: \", scores.mean())\n",
        "print(\"Number of CV Scores used in Average: \", len(scores))"
      ],
      "metadata": {
        "id": "IWc5D5QkJYew",
        "outputId": "48b601b0-ba9d-4d45-9b24-df7677849eca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross Validation Scores:  [1. 1. 1. ... 1. 1. 1.]\n",
            "Average CV Score:  0.9382997762863534\n",
            "Number of CV Scores used in Average:  11175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comme nous pouvons le voir, il s'agit d'une méthode exhaustive, nous calculons beaucoup plus de scores que Leave-One-Out, même avec ap = 2, mais elle atteint à peu près le même score CV moyen.\n",
        "\n",
        "Fractionnement aléatoire\n",
        "Contrairement à KFold, ShuffleSplitlaisse de côté un pourcentage des données, à ne pas utiliser dans les ensembles d'apprentissage ou de validation. Pour ce faire, nous devons décider de la taille des trains et des tests, ainsi que du nombre de fractionnements.\n",
        "\n",
        "Exemple\n",
        "Exécutez Shuffle Split CV :"
      ],
      "metadata": {
        "id": "QLN5gr3-JeoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
        "\n",
        "X, y = datasets.load_iris(return_X_y=True)\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "ss = ShuffleSplit(train_size=0.6, test_size=0.3, n_splits = 5)\n",
        "\n",
        "scores = cross_val_score(clf, X, y, cv = ss)\n",
        "\n",
        "print(\"Cross Validation Scores: \", scores)\n",
        "print(\"Average CV Score: \", scores.mean())\n",
        "print(\"Number of CV Scores used in Average: \", len(scores))"
      ],
      "metadata": {
        "id": "SXINi2QmJhwT",
        "outputId": "a52b3f0f-6454-4d37-93dd-6f0e555e78c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross Validation Scores:  [1.         0.95555556 0.97777778 0.95555556 0.93333333]\n",
            "Average CV Score:  0.9644444444444445\n",
            "Number of CV Scores used in Average:  5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes de fin\n",
        "Ce ne sont que quelques-unes des méthodes CV qui peuvent être appliquées aux modèles. Il existe de nombreuses autres classes de validation croisée, la plupart des modèles ayant leur propre classe. Consultez la validation croisée de sklearns pour plus d'options de CV."
      ],
      "metadata": {
        "id": "AC_7AlGxJkz2"
      }
    }
  ]
}